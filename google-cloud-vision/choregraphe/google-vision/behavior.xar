<?xml version="1.0" encoding="UTF-8" ?>
<ChoregrapheProject xmlns="http://www.aldebaran-robotics.com/schema/choregraphe/project.xsd" xar_version="3">
    <Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0">
        <bitmap>media/images/box/root.png</bitmap>
        <script language="4">
            <content>
                <![CDATA[]]>
</content>
        </script>
        <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
        <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
        <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
        <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
        <Timeline enable="0">
            <BehaviorLayer name="behavior_layer1">
                <BehaviorKeyframe name="keyframe1" index="1">
                    <Diagram>
                        <Box name="environment_setup" id="2" localization="8" tooltip="" x="413" y="253">
                            <bitmap>media/images/box/box-python-script.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[# ---------------------------------
# define globals
# ---------------------------------

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)

    def onLoad(self):
        print("onLoad")
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def onInput_onStart(self):
        self.onStopped() #activate the output of the box
        pass

    def onInput_onStop(self):
        self.onUnload() #it is recommended to reuse the clean-up as the box is stopped
        self.onStopped() #activate the output of the box]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                        </Box>
                        <Box name="Select Camera" id="4" localization="8" tooltip="Change the currently used camera." x="590" y="235">
                            <bitmap>media/images/box/interaction/look.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.kCameraSelectID = 18
        self.cameraModule = ALProxy( "ALVideoDevice" )

    def onLoad(self):
        pass

    def onUnload(self):
        pass

    def onInput_onUseTopCamera(self):
        self.cameraModule.setParam( self.kCameraSelectID, 0 )
        self.onReady()

    def onInput_onUseBottomCamera(self):
        self.cameraModule.setParam( self.kCameraSelectID, 1 )
        self.onReady()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onUseTopCamera" type="1" type_size="1" nature="1" inner="0" tooltip="Use the camera at the top of the head (forehead)." id="2" />
                            <Input name="onUseBottomCamera" type="1" type_size="1" nature="1" inner="0" tooltip="Use the camera at the bottom of the head (mouth)." id="3" />
                            <Output name="onReady" type="1" type_size="1" nature="2" inner="0" tooltip="The camera change is done." id="4" />
                            <Resource name="Camera setting" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Take Picture" id="5" localization="8" tooltip="Take a picture with one of the cameras camera and store it in his memory in ~/recordings/cameras. The image format is JPG.&#x0A;&#x0A;V1.1.0&#x0A;" x="763" y="212">
                            <bitmap>media/images/box/interaction/picture.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import os
import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.resolutionMap = {
            '160 x 120': 0,
            '320 x 240': 1,
            '640 x 480': 2,
            '1280 x 960': 3
        }
        self.cameraMap = {
            'Top': 0,
            'Bottom': 1
        }

        self.recordFolder = "/home/nao/recordings/cameras/"

    def onLoad(self):
        self.bIsRunning = False
        try:
            self.photoCapture = ALProxy( "ALPhotoCapture" )
        except Exception as e:
            self.photoCapture = None
            self.logger.error(e)

    def onUnload(self):
        pass

    def onInput_onStart(self):
        if( self.bIsRunning ):
            return
        self.bIsRunning = True
        resolution = self.resolutionMap[self.getParameter("Resolution")]
        cameraID = self.cameraMap[self.getParameter("Camera")]
        fileName = self.getParameter("File Name")
        if self.photoCapture:
            self.photoCapture.setResolution(resolution)
            self.photoCapture.setCameraID(cameraID)
            self.photoCapture.setPictureFormat("jpg")
            self.photoCapture.takePicture( self.recordFolder, fileName )
            image = os.path.join(self.recordFolder, fileName)
            self.log('Photo was saved in {}'.format(image))
        self.bIsRunning = False
        self.marvinViewPicture(image)]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Output name="marvinViewPicture" type="3" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="3" />
                            <Parameter name="Resolution" inherits_from_parent="0" content_type="3" value="1280 x 960" default_value="640 x 480" custom_choice="0" tooltip="Image resolution." id="4">
                                <Choice value="160 x 120" />
                                <Choice value="320 x 240" />
                                <Choice value="640 x 480" />
                                <Choice value="1280 x 960" />
                            </Parameter>
                            <Parameter name="File Name" inherits_from_parent="0" content_type="3" value="marvin_view.jpg" default_value="image" custom_choice="0" tooltip="Name of the file without its extension." id="5" />
                            <Parameter name="Camera" inherits_from_parent="0" content_type="3" value="Top" default_value="Top" custom_choice="0" tooltip="Enables to select the camera (Top or Bottom) that will take the picture." id="6">
                                <Choice value="Top" />
                                <Choice value="Bottom" />
                            </Parameter>
                        </Box>
                        <Box name="analyze_view" id="6" localization="8" tooltip="" x="952" y="224">
                            <bitmap>media/images/box/box-python-script.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import json
import requests
import os
import base64

VISION_URL="https://vision.googleapis.com/v1/images:annotate?key=AIzaSyBYQ6abjRtrhBsNCbY4vKqReGGi-lR9U7E"
TRANSLATE_URL="https://translation.googleapis.com/language/translate/v2?key=AIzaSyBYQ6abjRtrhBsNCbY4vKqReGGi-lR9U7E"

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.tts = ALProxy('ALTextToSpeech')

    def onLoad(self):
        # put initialization code here
        pass

    def onUnload(self):
        # put clean-up code here
        pass

    def encode_image(self, image_path):
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read())

    def doTextToSpeech(self, text):
        text = text.replace(" ", "%20")
        curl_cmd = " curl 'https://translate.google.com/translate_tts?ie=UTF-8&client=tw-ob&tl=ro&q=" + text + "' -H 'authority: translate.google.com' -H 'cache-control: max-age=0' -H 'upgrade-insecure-requests: 1' -H 'user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36' -H 'accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3' -H 'x-client-data: CLO1yQEIlbbJAQijtskBCMG2yQEI0bfJAQipncoBCKijygEIsafKAQjiqMoBCPGpygEIl63KAQjNrcoBCLGvygEIu6/KAQ==' -H 'accept-encoding: gzip, deflate, br' -H 'accept-language: en-US,en;q=0.9,ro;q=0.8' -H 'cookie: CONSENT=WP.27bda3; SID=lwfFcVA6MXjn4qNNUwy1jdH1CpbJ7vAA4CwVWAXw2Hw9d4xId8yUfXXXEs76cnfsmEwmMA.; HSID=ASUBigrScp8ho7gTp; SSID=AGzPzUYjhFLiMK3gp; APISID=uw-7VHw6-EbYXNli/AxTxLBSLH4YEAjOTg; SAPISID=4vlR9m4otE_pFiSG/AVK1kKLbhRQAl3mvs; ANID=AHWqTUmgBlWhaicge-ZLxGhABMnFQ4hXbYuMFcughFr4izaT1nDklIiu0wsxsNc3; NID=187=YkjyG5UdowPZZzCQsS_HeuJ4K5ndZVFoD02TetulilKSzdDNImBUvFRUTMr4D4rxdHmKdXqGX1bBB_Mo0KJPeEwvkz12IW1iOQaRzLi-kwyXm5s_hYTDV4ylyO7YgFf_TwpJyvnMVEphYK0av9940rfAOwH53Q6lKwNdDVOiGTX-sjHjAmLpc3DMWn_5QivfMjaN5pmJrl2Q6CvrPld9vbS7hn7ojZOIE9F_hyb4DfU; 1P_JAR=2019-7-9-12; SIDCC=AN0-TYtw0aldCg1M5UshM1rhzE9qrOROjM0KZgCfapJ7qJCCc5fIcjjx_HgbI_WwteCGPg3hdA' --compressed > /home/nao/google_speech.mp3"
        os.system(curl_cmd)


    def doTranslatePost(self, text):
        json_data = {
                    "q": text,
                    "target": "ro"
        }
        r = requests.post(TRANSLATE_URL, data=json.dumps(json_data))
        r_json = r.json()
        r_text= r_json['data']['translations'][0]['translatedText'].encode('utf-8')
        self.log(r_text)
        return r_text

    def doVisionPost(self, image_path):
        json_data = {
            "requests": [
                {
                    "image": {
                        "content": self.encode_image(image_path)
                    },
                    "features": [
                        {
                            "type": "LABEL_DETECTION",  # other options: LABEL_DETECTION FACE_DETECTION LOGO_DETECTION CROP_HINTS WEB_DETECTION
                            "maxResults": 3
                        }
                    ]
                }
            ]
        }
        r = requests.post(VISION_URL, data=json.dumps(json_data))
        return r.text

    def onInput_picture(self, p):
        self.log('Image location is {}'.format(p))
        self.log('Sending inference request to Google Vision API')
        text_answer = self.doVisionPost(p)
        api_answer = json.loads(text_answer)
        try:
            rows = api_answer['responses'][0]['labelAnnotations']
        except:
            print(api_answer)
            return;
        data = ""
        #self.tts.say('I see ')
        for item in rows:
            data=data + str(item['description']) + ","
        self.log(data)
        data_ro = self.doTranslatePost(data)
        self.log(data_ro)
        self.doTextToSpeech(data_ro)
        os.system("play /home/nao/google_speech.mp3")
        #self.tts.say(data)

    def onInput_onStop(self):
        self.onUnload()  # it is recommended to reuse the clean-up as the box is stopped
        self.onStopped()  # activate the output of the box]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="picture" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                        </Box>
                        <Box name="Set Speech Lang." id="1" localization="8" tooltip="Select the language you would like the robot to speak. Any following call to&#x0A;ALTextToSpeech (Say box for instance) will use this language." x="173" y="32">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy("ALTextToSpeech")

    def onInput_onSet(self):
        self.tts.setLanguage( self.getParameter("Language") )
        self.onReady()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onSet" type="1" type_size="1" nature="1" inner="0" tooltip="The data is set when a signal is received on this input." id="2" />
                            <Output name="onReady" type="1" type_size="1" nature="2" inner="0" tooltip="Signal sent when the data has been set." id="3" />
                            <Parameter name="Language" inherits_from_parent="0" content_type="3" value="English" default_value="English" custom_choice="1" tooltip="Set the language the robot speaks." id="4">
                                <Choice value="Arabic" />
                                <Choice value="Brazilian" />
                                <Choice value="Chinese" />
                                <Choice value="Czech" />
                                <Choice value="Danish" />
                                <Choice value="Dutch" />
                                <Choice value="English" />
                                <Choice value="Finnish" />
                                <Choice value="French" />
                                <Choice value="German" />
                                <Choice value="Italian" />
                                <Choice value="Japanese" />
                                <Choice value="Korean" />
                                <Choice value="Polish" />
                                <Choice value="Portuguese" />
                                <Choice value="Russian" />
                                <Choice value="Spanish" />
                                <Choice value="Swedish" />
                                <Choice value="Turkish" />
                            </Parameter>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Speech Reco." id="3" localization="8" tooltip="Recognize a word from a list of words set in the box parameters.&#x0A;&#x0A;V1.1.0&#x0A;" x="349" y="7">
                            <bitmap>media/images/box/interaction/ear.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        try:
            self.asr = ALProxy("ALSpeechRecognition")
        except Exception as e:
            self.asr = None
            self.logger.error(e)
        self.memory = ALProxy("ALMemory")

    def onLoad(self):
        from threading import Lock
        self.bIsRunning = False
        self.mutex = Lock()
        self.hasPushed = False
        self.hasSubscribed = False
        self.BIND_PYTHON(self.getName(), "onWordRecognized")

    def onUnload(self):
        from threading import Lock
        self.mutex.acquire()
        try:
            if (self.bIsRunning):
                if (self.hasSubscribed):
                    self.memory.unsubscribeToEvent("WordRecognized", self.getName())
                if (self.hasPushed and self.asr):
                    self.asr.popContexts()
        except RuntimeError, e:
            self.mutex.release()
            raise e
        self.bIsRunning = False;
        self.mutex.release()

    def onInput_onStart(self):
        from threading import Lock
        self.mutex.acquire()
        if(self.bIsRunning):
            self.mutex.release()
            return
        self.bIsRunning = True
        try:
            if self.asr:
                self.asr.setVisualExpression(self.getParameter("Visual expression"))
                self.asr.pushContexts()
            self.hasPushed = True
            if self.asr:
                self.asr.setVocabulary( self.getParameter("Word list").split(';'), self.getParameter("Enable word spotting") )
            self.memory.subscribeToEvent("WordRecognized", self.getName(), "onWordRecognized")
            self.hasSubscribed = True
        except RuntimeError, e:
            self.mutex.release()
            self.onUnload()
            raise e
        self.mutex.release()

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()

    def onWordRecognized(self, key, value, message):
        if(len(value) > 1 and value[1] >= self.getParameter("Confidence threshold (%)")/100.):
            self.wordRecognized(value[0]) #~ activate output of the box
        else:
            self.onNothing()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                            <Output name="wordRecognized" type="3" type_size="1" nature="2" inner="0" tooltip="Word recognized with a confidence higher than the threshold set in the box parameters." id="5" />
                            <Output name="onNothing" type="1" type_size="1" nature="2" inner="0" tooltip="Nothing has been understood." id="6" />
                            <Parameter name="Word list" inherits_from_parent="0" content_type="3" value="detect" default_value="yes;no" custom_choice="0" tooltip="Try to recognize a word from a list of words set in the box parameters." id="7" />
                            <Parameter name="Confidence threshold (%)" inherits_from_parent="0" content_type="1" value="30" default_value="30" min="0" max="100" tooltip="If the confidence associated with the word recognized is below this threshold, the robot will consider that it is not recognized." id="8" />
                            <Parameter name="Visual expression" inherits_from_parent="0" content_type="0" value="1" default_value="1" tooltip="Use the LEDs to show feedbacks from the robot during the recognition.&#x0A;&#x0A;For example:&#x0A;- Eyes leds get blue and turn when the speech recognition is launched.&#x0A;- They get yellow when the robot hears someone talking and analyses what it heard.&#x0A;- They flash in green when the robot understood and flash in red otherwise." id="9" />
                            <Parameter name="Enable word spotting" inherits_from_parent="0" content_type="0" value="0" default_value="0" tooltip="If this option is not activated the robot will only understand exact expressions. If it is, he will spot the exact expressions even in the middle of a sentence.&#x0A;&#x0A;!!Warning!! This option is only available with the speech recognition module using Nuance (ie in Atom version of the robot)." id="10" />
                            <Resource name="Speech recognition" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Tactile Head" id="7" localization="8" tooltip="Detect touch on head tactile sensor." x="199" y="248">
                            <bitmap>media/images/box/sensors/tactileHead.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload() #~ it is usually a good idea to call onUnload of this box in a onStop method, as the code written in onUnload is used to finish the working of the box as well
            self.onStopped() #~ activate output of the box
        pass]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Input name="FrontTactilTouched" type="0" type_size="1" nature="4" stm_value_name="FrontTactilTouched" inner="1" tooltip="Connected to ALMemory. Will be stimulated every time the value subscribed to changes, respecting the refresh period." id="4" />
                            <Input name="MiddleTactilTouched" type="0" type_size="1" nature="4" stm_value_name="MiddleTactilTouched" inner="1" tooltip="Connected to ALMemory. Will be stimulated every time the value subscribed to changes, respecting the refresh period." id="5" />
                            <Input name="RearTactilTouched" type="0" type_size="1" nature="4" stm_value_name="RearTactilTouched" inner="1" tooltip="Connected to ALMemory. Will be stimulated every time the value subscribed to changes, respecting the refresh period." id="6" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is stopped." id="7" />
                            <Output name="frontTouched" type="1" type_size="1" nature="2" inner="0" tooltip="The front tactile head sensor was touched." id="8" />
                            <Output name="middleTouched" type="1" type_size="1" nature="2" inner="0" tooltip="The middle tactile head sensor was touched." id="9" />
                            <Output name="rearTouched" type="1" type_size="1" nature="2" inner="0" tooltip="The rear tactile head sensor was touched." id="10" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="If &gt; 0" id="1" localization="8" tooltip="Transmit only if value is &gt; 0." x="260" y="17">
                                                <bitmap>media/images/box/box-diagram.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        #~ puts code for box initialization here
        pass

    def onUnload(self):
        #~ puts code for box cleanup here
        pass

    def onInput_onStart(self, p):
        if(p > 0):
            self.onStopped() #~ activate output of the box
        pass

    def onInput_onStop(self):
        self.onUnload() #~ it is usually a good idea to call onUnload of this box in a onStop method, as the code written in onUnload is used to finish the working of the box as well
        pass]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="0" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                                            </Box>
                                            <Box name="If &gt; 0" id="2" localization="8" tooltip="Transmit only if value is &gt; 0." x="256" y="119">
                                                <bitmap>media/images/box/box-diagram.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        #~ puts code for box initialization here
        pass

    def onUnload(self):
        #~ puts code for box cleanup here
        pass

    def onInput_onStart(self, p):
        if(p > 0):
            self.onStopped() #~ activate output of the box
        pass

    def onInput_onStop(self):
        self.onUnload() #~ it is usually a good idea to call onUnload of this box in a onStop method, as the code written in onUnload is used to finish the working of the box as well
        pass]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="0" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                                            </Box>
                                            <Box name="If &gt; 0" id="3" localization="8" tooltip="Transmit only if value is &gt; 0." x="261" y="223">
                                                <bitmap>media/images/box/box-diagram.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        #~ puts code for box initialization here
        pass

    def onUnload(self):
        #~ puts code for box cleanup here
        pass

    def onInput_onStart(self, p):
        if(p > 0):
            self.onStopped() #~ activate output of the box
        pass

    def onInput_onStop(self):
        self.onUnload() #~ it is usually a good idea to call onUnload of this box in a onStop method, as the code written in onUnload is used to finish the working of the box as well
        pass]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="0" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                                            </Box>
                                            <Link inputowner="1" indexofinput="2" outputowner="0" indexofoutput="4" />
                                            <Link inputowner="0" indexofinput="8" outputowner="1" indexofoutput="4" />
                                            <Link inputowner="2" indexofinput="2" outputowner="0" indexofoutput="5" />
                                            <Link inputowner="0" indexofinput="9" outputowner="2" indexofoutput="4" />
                                            <Link inputowner="3" indexofinput="2" outputowner="0" indexofoutput="6" />
                                            <Link inputowner="0" indexofinput="10" outputowner="3" indexofoutput="4" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                            <Resource name="Head-sequence" type="Lock" timeout="0" />
                        </Box>
                        <Link inputowner="5" indexofinput="2" outputowner="4" indexofoutput="4" />
                        <Link inputowner="6" indexofinput="2" outputowner="5" indexofoutput="3" />
                        <Link inputowner="4" indexofinput="2" outputowner="2" indexofoutput="4" />
                        <Link inputowner="3" indexofinput="2" outputowner="1" indexofoutput="3" />
                        <Link inputowner="1" indexofinput="2" outputowner="0" indexofoutput="2" />
                        <Link inputowner="2" indexofinput="2" outputowner="3" indexofoutput="5" />
                        <Link inputowner="7" indexofinput="2" outputowner="0" indexofoutput="2" />
                        <Link inputowner="2" indexofinput="2" outputowner="7" indexofoutput="8" />
                        <Link inputowner="2" indexofinput="2" outputowner="7" indexofoutput="9" />
                        <Link inputowner="2" indexofinput="2" outputowner="7" indexofoutput="10" />
                    </Diagram>
                </BehaviorKeyframe>
            </BehaviorLayer>
        </Timeline>
    </Box>
</ChoregrapheProject>
